{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydicom\n",
    "import torch\n",
    "from model import RegressionModel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import load\n",
    "import nibabel as nib \n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path of the ct scan\n",
    "path = 'ct_scans/chest_ct/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the dicom examination and sort the slices based on the slice location\n",
    "def read_dicom(path):\n",
    "\n",
    "    slices = [pydicom.dcmread(path + '/' + s, force=True) for s in os.listdir(path)]\n",
    "    slices.sort(key = lambda x: float(x.ImagePositionPatient[2]))\n",
    "    return slices\n",
    "\n",
    "dicom_image_serie = read_dicom(path)\n",
    "\n",
    "#convert the dicom image to a numpy array\n",
    "def dicom_to_array(slices):\n",
    "        \n",
    "    image = np.stack([s.pixel_array for s in slices])\n",
    "    image = image.astype(np.int16)\n",
    "    return image\n",
    "\n",
    "dicom_image_array = dicom_to_array(dicom_image_serie)\n",
    "\n",
    "#converting pixel values to Hounsfield units\n",
    "def convert_to_hu(dicom_image_serie, dicom_image_array):\n",
    "    intercept = dicom_image_serie[0].RescaleIntercept\n",
    "    slope = dicom_image_serie[0].RescaleSlope\n",
    "    hu_image = dicom_image_array * slope + intercept\n",
    "    return hu_image\n",
    "\n",
    "hu_image = convert_to_hu(dicom_image_serie, dicom_image_array)\n",
    "\n",
    "#extracting mA values\n",
    "mA = [s.XRayTubeCurrent for s in dicom_image_serie]\n",
    "mean_mA = np.mean(mA)\n",
    "\n",
    "#extracting slice location\n",
    "slice_location = [s.SliceLocation for s in dicom_image_serie]\n",
    "\n",
    "#creating organ masks\n",
    "os.makedirs('inference/organ_masks', exist_ok=True)\n",
    "\n",
    "os.system('TotalSegmentator -i %s -o %s' %(path, 'inference/organ_masks/'))\n",
    "os.system('TotalSegmentator -i %s -o %s -ta body' % (path, 'inference/organ_masks/'))\n",
    "os.system('TotalSegmentator -i %s -o %s -ta lung_vessels' % (path, 'inference/organ_masks/'))\n",
    "\n",
    "#WED calculation\n",
    "\n",
    "#voxel x and y dimensions\n",
    "x_dim = float(dicom_image_serie[0].PixelSpacing[0])\n",
    "y_dim = float(dicom_image_serie[0].PixelSpacing[1])\n",
    "\n",
    "body_mask = np.rot90(nib.load('inference/organ_masks/body.nii.gz').get_fdata())\n",
    "\n",
    "#transose the array to match the dimensions of the hu_image\n",
    "body_mask = np.transpose(body_mask, (2, 0, 1))\n",
    "body_mask[body_mask != 1] = np.nan\n",
    "\n",
    "wed_array = []\n",
    "\n",
    "for j in range(0, len(dicom_image_serie)):\n",
    "    pix_number = np.count_nonzero(body_mask[j] == 1)\n",
    "    area = pix_number*x_dim*y_dim\n",
    "    croped = hu_image[j]*body_mask[j]\n",
    "    mean_HU = np.nanmean(croped)\n",
    "    wed = 2*(math.sqrt(((mean_HU/1000)+1)*(area/math.pi)))\n",
    "    wed_array.append(wed)\n",
    "\n",
    "#inference array creation\n",
    "\n",
    "def inference_array(organ):\n",
    "    mask = np.rot90(nib.load('inference/organ_masks/' + organ + '.nii.gz').get_fdata())\n",
    "    mask = np.transpose(mask, (2, 0, 1))\n",
    "    mask[mask != 1] = np.nan\n",
    "\n",
    "    #retrieving the organ's HU values\n",
    "    masked_organ = hu_image*mask\n",
    "\n",
    "    organ_training_array = np.empty((len(dicom_image_serie), 5), dtype=np.float32)\n",
    "    idx = []\n",
    "    for j in range(len(dicom_image_serie)):\n",
    "        if np.all(np.isnan(masked_organ[j])):\n",
    "            idx.append(j)\n",
    "        else:\n",
    "            organ_training_array[j][0] = np.nanmean(masked_organ[j])\n",
    "            organ_training_array[j][1] = np.nanstd(masked_organ[j])\n",
    "            organ_training_array[j][2] = float(mA[j])\n",
    "            organ_training_array[j][3] = wed_array[j]\n",
    "            organ_training_array[j][4] = float(slice_location[j])\n",
    "\n",
    "    clean_organ_training_array = np.delete(organ_training_array, idx, axis=0)\n",
    "\n",
    "    #save the inference array\n",
    "    os.makedirs('inference/inference_arrays/' + organ, exist_ok=True)\n",
    "    file_name = f'inference/inference_arrays/{organ}/{organ}_inference_array.npy'\n",
    "    np.save(file_name, clean_organ_training_array)\n",
    "    \n",
    "\n",
    "\n",
    "organs_list = ['esophagus', 'aorta', 'pulmonary_artery', 'lung_lower_lobe_left', 'lung_lower_lobe_right',\n",
    "                'lung_upper_lobe_left', 'lung_upper_lobe_right', 'lung_middle_lobe_right', \n",
    "                'heart_atrium_left', 'heart_atrium_right', 'heart_ventricle_left', 'heart_ventricle_right', \n",
    "                'heart_myocardium', 'skin', 'lung', 'lung_vessels', 'lung_trachea_bronchia', 'thyroid_gland']\n",
    "\n",
    "\n",
    "for organ in organs_list:\n",
    "    inference_array(organ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dose prediction\n",
    "\n",
    "#model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "hidden_sizes = [512, 256, 128, 64]\n",
    "model = RegressionModel(input_size=5, hidden_sizes=hidden_sizes, output_size=1, num_layers=5, dropout=0.1)\n",
    "\n",
    "print('Predicted dose for the organs of interest' )\n",
    "print('-----------------------------------------')\n",
    "\n",
    "def evaluate(organ):\n",
    "\n",
    "    #model loading for the organ\n",
    "    model.load_state_dict(torch.load('chest_models/'+ organ + '_model.pth'))\n",
    "    model.to(device)\n",
    "\n",
    "    #scaler for the organ\n",
    "    data = load('training_arrays/chest_merged_training_arrays/'+ organ + '_training_array.npy')\n",
    "\n",
    "    X = data[:,:-1]\n",
    "\n",
    "    # Find rows containing NaN values in X\n",
    "    nan_rows_X = np.isnan(X).any(axis=1)\n",
    "\n",
    "    # Drop rows with NaN values from X \n",
    "    X = X[~nan_rows_X]\n",
    "\n",
    "    # fit scaler \n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    \n",
    "    X_test  = load(f'inference/inference_arrays/{organ}/{organ}_inference_array.npy')\n",
    "    \n",
    "    # Find rows containing NaN values in X\n",
    "    nan_rows_X_test = np.isnan(X_test).any(axis=1)\n",
    "\n",
    "    # Drop rows with NaN values from X and y\n",
    "    X_test = X_test[~nan_rows_X_test]\n",
    "    \n",
    "    #scaling\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    #data to tensor\n",
    "    X_test = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "\n",
    "    #evaluate\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        predictions = model(X_test).cpu().numpy()\n",
    "\n",
    "\n",
    "    print(f'{organ} : {np.mean(predictions):.1f} mGy')   \n",
    "\n",
    "organs_list = ['esophagus', 'aorta', 'pulmonary_artery', 'lung_lower_lobe_left', 'lung_lower_lobe_right',\n",
    "                'lung_upper_lobe_left', 'lung_upper_lobe_right', 'lung_middle_lobe_right', \n",
    "                'heart_atrium_left', 'heart_atrium_right', 'heart_ventricle_left', 'heart_ventricle_right', \n",
    "                'heart_myocardium', 'skin', 'lung', 'lung_vessels', 'lung_trachea_bronchia', 'thyroid_gland']\n",
    "\n",
    "\n",
    "for organ in organs_list:\n",
    "    evaluate(organ)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "totalsegmentator",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
